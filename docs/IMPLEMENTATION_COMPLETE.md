# âœ… MATILDA Benchmark Automation - COMPLET

## ğŸ‰ RÃ©sumÃ©

Vous avez maintenant **3 scripts** pour gÃ©nÃ©rer des tableaux LaTeX avec vos rÃ©sultats MATILDA :

### 1. `run_full_benchmark.py` â­ NOUVEAU !

**Le script ONE-CLICK pour tout automatiser**

```bash
python run_full_benchmark.py --runs 5
```

**Ce qu'il fait :**
- âœ… ExÃ©cute **TOUS** les algorithmes (MATILDA, SPIDER, ANYBURL, POPPER)
- âœ… Sur **TOUS** les datasets (Bupa, BupaImperfect, ComparisonDataset, ImperfectTest)
- âœ… **N fois** chaque combinaison
- âœ… Calcule **moyenne Â± Ã©cart-type** automatiquement
- âœ… GÃ©nÃ¨re **table LaTeX professionnelle** avec stats
- âœ… Sauvegarde tout en JSON

**Temps :** 1-4h selon N runs  
**Usage :** Article scientifique complet

---

### 2. `run_benchmark.py`

**Pour tester un algorithme spÃ©cifique avec stats**

```bash
python run_benchmark.py --runs 5 --algorithms MATILDA
```

**Ce qu'il fait :**
- âœ… ExÃ©cute **UN** algorithme N fois
- âœ… Calcule statistiques
- âœ… GÃ©nÃ¨re table LaTeX

**Temps :** 5-30 min  
**Usage :** Test d'un algorithme

---

### 3. `generate_latex_table.py`

**Pour gÃ©nÃ©rer une table depuis rÃ©sultats existants**

```bash
python generate_latex_table.py --detailed
```

**Ce qu'il fait :**
- âœ… Table LaTeX depuis fichiers JSON existants
- âŒ Pas de re-exÃ©cution
- âŒ Pas de statistiques

**Temps :** < 1 seconde  
**Usage :** Table rapide

---

## ğŸ“‹ Fichiers CrÃ©Ã©s

### Scripts Python
- âœ… `run_full_benchmark.py` (nouveau, ~400 lignes)
- âœ… `run_benchmark.py` (~300 lignes)
- âœ… `generate_latex_table.py` (~350 lignes)
- âœ… `test_latex_generation.py` (~150 lignes)

### Configuration
- âœ… `benchmark_config.yaml` - Config pour benchmark complet

### Documentation
- âœ… `BENCHMARKING_QUICKSTART.md` - Guide rapide â­
- âœ… `FULL_BENCHMARK_GUIDE.md` - Guide `run_full_benchmark.py`
- âœ… `LATEX_TABLES_GUIDE.md` - Guide `run_benchmark.py`
- âœ… `LATEX_README.md` - Guide `generate_latex_table.py`
- âœ… `WHICH_SCRIPT.md` - Arbre de dÃ©cision (mis Ã  jour)
- âœ… `LATEX_SUMMARY.md` - RÃ©fÃ©rence ultra-concise

### Exemples
- âœ… `data/output/example_document.tex`
- âœ… `data/output/example_stats_table.tex`

---

## ğŸš€ Pour Commencer

### Cas 1 : Article Scientifique (RecommandÃ©)

```bash
# Une seule commande !
python run_full_benchmark.py --runs 5

# Copier la table dans votre article
cp data/output/benchmark_table_*.tex paper/tables/
```

DurÃ©e : 1-2 heures  
RÃ©sultat : Table professionnelle avec statistiques

---

### Cas 2 : Test Rapide

```bash
# VÃ©rifier que tout marche (< 5 min)
python run_full_benchmark.py --runs 1 --algorithms MATILDA --datasets Bupa
```

---

### Cas 3 : PrÃ©sentation Urgente

```bash
# Table immÃ©diate depuis rÃ©sultats existants (< 1s)
python generate_latex_table.py --detailed
```

---

## ğŸ“Š Formats de Sortie

### Table Simple (6 colonnes)

| Algorithm | Dataset | #Rules | Accuracy | Confidence | Time (s) |
|-----------|---------|--------|----------|------------|----------|

### Table DÃ©taillÃ©e (8 colonnes)

| Algorithm | Dataset | #Rules | Acc. | Conf. | T_compat | T_index | T_CG |
|-----------|---------|--------|------|-------|----------|---------|------|

### Avec Statistiques (N runs)

Format : `$9 \pm 0.0$` (moyenne Â± Ã©cart-type)

```latex
MATILDA & Bupa & $9 \pm 0.0$ & $1.000 \pm 0.000$ & ...
```

---

## ğŸ¯ Options Principales

### `run_full_benchmark.py`

```bash
# Nombre de runs
--runs 5

# Algorithmes spÃ©cifiques
--algorithms MATILDA SPIDER

# Datasets spÃ©cifiques
--datasets Bupa BupaImperfect

# Type de table
--table-type detailed  # ou simple

# Fichier de config
--config benchmark_config.yaml

# Mode silencieux
--quiet
```

### Exemples

```bash
# Benchmark complet (dÃ©faut)
python run_full_benchmark.py --runs 5

# Rapide (3 runs, 2 algos)
python run_full_benchmark.py --runs 3 --algorithms MATILDA SPIDER

# Avec config
python run_full_benchmark.py --config benchmark_config.yaml

# Table simple
python run_full_benchmark.py --runs 5 --table-type simple
```

---

## ğŸ“ Fichiers de Sortie

### ExÃ©cution du `run_full_benchmark.py`

```
data/output/
â”œâ”€â”€ full_benchmark_results_20260112_143020.json      # RÃ©sultats bruts
â”œâ”€â”€ full_benchmark_statistics_20260112_143020.json   # Statistiques
â””â”€â”€ benchmark_table_20260112_143020.tex              # Table LaTeX
```

### Contenu JSON Statistiques

```json
{
  "MATILDA": {
    "Bupa": {
      "num_rules": {"mean": 9.0, "std": 0.0},
      "accuracy": {"mean": 1.0, "std": 0.0},
      "time_total": {"mean": 0.124, "std": 0.002},
      "n_runs": 5
    }
  }
}
```

---

## â±ï¸ Temps d'ExÃ©cution

| Commande | Temps | Usage |
|----------|-------|-------|
| `generate_latex_table.py` | < 1s | Table rapide |
| `run_benchmark.py --runs 5` | 5-15 min | Test 1 algo |
| `run_full_benchmark.py --runs 3` | 30-60 min | Benchmark rapide |
| `run_full_benchmark.py --runs 5` | 1-2h | Article standard |
| `run_full_benchmark.py --runs 10` | 3-4h | Publication prestige |

---

## ğŸ§ª Tester

```bash
# VÃ©rifier installation
python test_latex_generation.py

# Test ultra-rapide (< 1 min)
python run_full_benchmark.py --runs 1 --algorithms MATILDA --datasets Bupa
```

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| **[BENCHMARKING_QUICKSTART.md](BENCHMARKING_QUICKSTART.md)** | **Guide rapide complet** â­ |
| [FULL_BENCHMARK_GUIDE.md](FULL_BENCHMARK_GUIDE.md) | Guide dÃ©taillÃ© `run_full_benchmark.py` |
| [WHICH_SCRIPT.md](WHICH_SCRIPT.md) | Arbre de dÃ©cision : quel script choisir ? |
| [LATEX_TABLES_GUIDE.md](LATEX_TABLES_GUIDE.md) | Guide `run_benchmark.py` |
| [LATEX_README.md](LATEX_README.md) | Guide `generate_latex_table.py` |
| [LATEX_SUMMARY.md](LATEX_SUMMARY.md) | RÃ©fÃ©rence ultra-concise |
| [benchmark_config.yaml](benchmark_config.yaml) | Configuration exemple |

---

## ğŸ’¡ Conseils

### Pour Gagner du Temps

```bash
# Moins de runs
python run_full_benchmark.py --runs 3

# Exclure algorithmes lents
python run_full_benchmark.py --runs 5 --algorithms MATILDA SPIDER
```

### Pour Publication

```bash
# 5+ runs recommandÃ©s
python run_full_benchmark.py --runs 5

# 10 runs pour reviewers exigeants
python run_full_benchmark.py --runs 10
```

### ExÃ©cuter en ArriÃ¨re-Plan

```bash
# Lancer et continuer Ã  travailler
nohup python run_full_benchmark.py --runs 5 > benchmark.log 2>&1 &

# Suivre progression
tail -f benchmark.log
```

---

## ğŸ†˜ RÃ©solution de ProblÃ¨mes

### "Timeout expired"

```bash
# Augmenter timeout (2h)
python run_full_benchmark.py --runs 5 --timeout 7200
```

### "Certains runs Ã©chouent"

Le script continue mÃªme si certains runs Ã©chouent. Les statistiques sont calculÃ©es sur les runs rÃ©ussis uniquement.

### "Trop lent"

```bash
# ExÃ©cuter par morceaux
python run_full_benchmark.py --runs 5 --algorithms MATILDA
python run_full_benchmark.py --runs 5 --algorithms SPIDER
# etc.
```

---

## âœ… Checklist Article

- [ ] **ExÃ©cuter benchmark**
  ```bash
  python run_full_benchmark.py --runs 5
  ```

- [ ] **VÃ©rifier rÃ©sultats**
  - Fichiers JSON crÃ©Ã©s ? âœ“
  - Table LaTeX gÃ©nÃ©rÃ©e ? âœ“
  - Statistiques raisonnables (std < 10% mean) ? âœ“

- [ ] **IntÃ©grer dans article**
  ```bash
  cp data/output/benchmark_table_*.tex paper/tables/results.tex
  ```

- [ ] **Compiler article**
  ```bash
  cd paper && pdflatex main.tex
  ```

- [ ] **Documenter mÃ©thodologie**
  - Nombre de runs : 5
  - Algorithmes : MATILDA, SPIDER, ANYBURL, POPPER
  - Datasets : Bupa, BupaImperfect, ComparisonDataset, ImperfectTest
  - Timeout : 1h par run
  - Machine : [spÃ©cifier CPU/RAM]

- [ ] **Sauvegarder donnÃ©es**
  - `full_benchmark_results_*.json`
  - `full_benchmark_statistics_*.json`
  - Logs si nÃ©cessaire

---

## ğŸ“ RÃ©capitulatif

### Vous avez maintenant :

âœ… **3 scripts Python** pour tous vos besoins de benchmarking  
âœ… **Configuration YAML** flexible  
âœ… **Tests automatisÃ©s** pour vÃ©rifier que tout marche  
âœ… **7 fichiers de documentation** complets  
âœ… **Exemples LaTeX** prÃªts Ã  l'emploi  

### Le plus simple :

```bash
# Pour article scientifique
python run_full_benchmark.py --runs 5

# Pour table rapide
python generate_latex_table.py --detailed
```

---

## ğŸ¯ Prochaines Ã‰tapes

1. **Tester le systÃ¨me**
   ```bash
   python test_latex_generation.py
   ```

2. **Lancer un benchmark test**
   ```bash
   python run_full_benchmark.py --runs 1 --algorithms MATILDA --datasets Bupa
   ```

3. **Benchmark complet pour article**
   ```bash
   python run_full_benchmark.py --runs 5
   ```

4. **IntÃ©grer dans votre article**
   ```bash
   cp data/output/benchmark_table_*.tex paper/tables/
   ```

---

**ğŸ‰ SystÃ¨me complet et prÃªt Ã  l'emploi !**

**Question ? Consultez [BENCHMARKING_QUICKSTART.md](BENCHMARKING_QUICKSTART.md) ou [WHICH_SCRIPT.md](WHICH_SCRIPT.md)**
