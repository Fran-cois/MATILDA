# üöÄ T2.1 - Impl√©mentation des Heuristiques - COMPL√âT√â

## ‚úÖ Livrables

### 1. Module Heuristiques (`src/heuristics/`)
Cr√©√© le module complet avec 4 heuristiques pour optimiser la recherche de chemins:

#### **path_search.py** (240+ lignes)
Classe `PathSearchHeuristics` avec 4 heuristiques:

1. **Naive Heuristic**
   - Pr√©f√®re les r√®gles plus courtes (moins de tables)
   - Complexit√©: O(n) o√π n = nombre de JIA
   - Usage: Baseline simple

2. **Table Size Heuristic** 
   - Favorise les r√®gles avec tables plus petites (plus rapides √† √©valuer)
   - Cache les tailles de tables pour performance
   - Normalise par nombre de tables pour √©quit√©
   - Usage: Optimisation computationnelle

3. **Join Selectivity Heuristic**
   - Estime la taille du r√©sultat apr√®s jointures
   - Selectivit√© par d√©faut: 0.1 (10% du produit cart√©sien)
   - Utilise log scaling pour g√©rer croissance exponentielle
   - Usage: Pr√©diction de co√ªt de requ√™te

4. **Hybrid Heuristic** ‚≠ê (Recommand√©)
   - Combine les 3 heuristiques avec poids:
     - Complexit√© (30%)
     - Table Size (40%)
     - Join Selectivity (30%)
   - Normalisation pour comparaison √©quitable
   - Usage: Meilleur compromis qualit√©/performance

#### **Fonctionnalit√©s**
- Factory function `create_heuristic()` pour instanciation simple
- Cache des m√©tadonn√©es de tables (tailles)
- Gestion des erreurs (tables inconnues, donn√©es manquantes)
- Interface uniforme pour A-star

### 2. Script de Benchmarking

#### **benchmark_traversal.py** (450+ lignes)
Script complet pour comparer algorithmes et heuristiques:

**Configurations test√©es:**
1. DFS (baseline naive)
2. BFS
3. A-star + Naive
4. A-star + Table Size
5. A-star + Join Selectivity  
6. A-star + Hybrid

**M√©triques mesur√©es:**
- ‚è±Ô∏è Temps total d'ex√©cution
- üéØ Temps jusqu'√† premi√®re r√®gle
- üìä Nombre de r√®gles d√©couvertes
- ‚ö° R√®gles par seconde
- üíæ M√©moire (peak & current)

**Fonctionnalit√©s:**
- Benchmark individuel ou suite compl√®te
- Limites configurables (max_rules, timeout)
- Sauvegarde JSON des r√©sultats
- Tableau de comparaison avec meilleursperformers
- Support tracemalloc pour profiling m√©moire

**Usage:**
```bash
# Benchmark complet (6 configs)
python scripts/benchmarks/benchmark_traversal.py data/db/BupaImperfect.db

# Benchmark rapide
python scripts/benchmarks/benchmark_traversal.py data/db/BupaImperfect.db --quick

# Benchmark sp√©cifique
python scripts/benchmarks/benchmark_traversal.py data/db/BupaImperfect.db \
  --algorithm astar --heuristic hybrid --max-rules 50

# Via CLI
python cli.py heuristics --quick
python cli.py heuristics data/db/BupaImperfect.db --algorithm astar --heuristic hybrid
```

### 3. Int√©gration CLI

**Nouvelle commande:** `python cli.py heuristics`

**Options:**
- `--quick`: Benchmark rapide (20 r√®gles, 60s timeout)
- `--algorithm {dfs,bfs,astar}`: Benchmarker un seul algorithme
- `--heuristic {naive,table_size,join_selectivity,hybrid}`: Heuristique pour A-star
- `--max-rules N`: Limite de r√®gles (d√©faut: 50)
- `--timeout N`: Timeout en secondes (d√©faut: 300)
- `--output-dir PATH`: Dossier de sortie

### 4. Tests Unitaires

#### **test_heuristics.py** (290+ lignes)
Suite de tests compl√®te avec mocks:

**Classes test√©es:**
- `TestPathSearchHeuristics`: 13 tests principaux
- `TestEdgeCases`: Tests de robustesse

**Couverture:**
- ‚úÖ Initialization avec cache des tables
- ‚úÖ Chaque heuristique (naive, table_size, join_selectivity, hybrid)
- ‚úÖ Factory function
- ‚úÖ Consistance des r√©sultats
- ‚úÖ Ordering correct (r√®gles simples < complexes)
- ‚úÖ Edge cases (r√®gles vides, tables inconnues)
- ‚úÖ Non-n√©gativit√© des co√ªts

**Mocks cr√©√©s:**
- `MockIndexedAttribute`: Simule IndexedAttribute
- `MockAttributeMapper`: Simule mapper avec 3 tables
- `MockDBInspector`: Retourne tailles mock√©es (table1: 1000, table2: 5000, table3: 500)

### 5. Documentation

#### **Mise √† jour GRAPH_TRAVERSAL_ALGORITHMS.md**
La documentation existante couvrait d√©j√† DFS/BFS/A-star. Cette impl√©mentation ajoute:
- 4 heuristiques concr√®tes pour A-star
- Benchmark comparatif des performances
- Guide d'utilisation pratique

---

## üìä R√©sultats Attendus

### Comparaison Th√©orique des Algorithmes

| Algorithme | M√©moire | Premi√®re R√®gle | R√®gles Complexes | Compl√©tude |
|-----------|---------|----------------|------------------|-----------|
| **DFS** (naive) | Faible | Moyenne | Rapide | Oui |
| **BFS** | √âlev√©e | Rapide | Lente | Oui |
| **A* + Naive** | Moyenne | Rapide | Moyenne | Partielle |
| **A* + Table Size** | Moyenne | Rapide | Rapide | Partielle |
| **A* + Hybrid** ‚≠ê | Moyenne | Tr√®s Rapide | Rapide | Partielle |

### Cas d'Usage Recommand√©s

1. **DFS (default)**: 
   - M√©moire limit√©e
   - R√®gles complexes en priorit√©
   - Comportement historique de MATILDA

2. **BFS**: 
   - Explorer r√®gles simples d'abord
   - Analyse exhaustive niveau par niveau
   - M√©moire abondante

3. **A-star + Hybrid** ‚≠ê:
   - **Meilleur compromis g√©n√©ral**
   - D√©couverte rapide de r√®gles de qualit√©
   - Optimisation temps/m√©moire/qualit√©

4. **A-star + Table Size**:
   - Bases avec tables de tailles vari√©es
   - Optimisation du temps de requ√™te
   - Focus sur performance computationnelle

5. **A-star + Join Selectivity**:
   - Sch√©mas avec nombreuses jointures
   - √âviter explosion combinatoire
   - Bases large-scale

---

## üîÑ Prochaines √âtapes (T2.2)

**T2.2 - Sensitivity Analysis (N parameter)**
Maintenant que les heuristiques sont impl√©ment√©es et benchmarkables, nous pouvons:

1. Analyser l'impact du param√®tre N (max_table) sur:
   - Temps de d√©couverte
   - Nombre de r√®gles trouv√©es
   - Qualit√© des r√®gles (confidence, support)

2. Tester avec diff√©rentes heuristiques pour voir laquelle est la plus stable

3. D√©terminer la configuration optimale (algorithme + heuristique + N) pour diff√©rents sc√©narios

---

## üì¶ Fichiers Cr√©√©s

```
src/heuristics/
‚îú‚îÄ‚îÄ __init__.py                           # Module init avec exports
‚îî‚îÄ‚îÄ path_search.py                        # 4 heuristiques + factory

scripts/benchmarks/
‚îî‚îÄ‚îÄ benchmark_traversal.py                # Script de benchmarking (450 lignes)

tests/
‚îî‚îÄ‚îÄ test_heuristics.py                    # Tests unitaires (290 lignes)

cli.py                                     # Ajout commande 'heuristics'

docs/
‚îî‚îÄ‚îÄ T2.1_HEURISTICS_COMPLETE.md           # Ce fichier
```

---

## ‚úÖ Validation

- [x] Module heuristics cr√©√© avec 4 heuristiques
- [x] Script benchmark_traversal.py fonctionnel
- [x] Int√©gration CLI avec commande `heuristics`
- [x] Tests unitaires cr√©√©s (13+ tests)
- [x] Documentation mise √† jour
- [x] Comparaison DFS vs BFS vs A-star possible
- [x] Factory pattern pour instanciation facile
- [x] Gestion des edge cases et erreurs

**Status: T2.1 COMPL√âT√â ‚úÖ**

Pr√™t pour lancer les benchmarks sur Bupa et passer √† T2.2 (Sensitivity Analysis).
