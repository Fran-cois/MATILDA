# üìä Mise √† Jour : Analyse des M√©triques de Temps de Calcul

**Date :** 12 janvier 2026  
**Version :** 2.1  
**Fonctionnalit√© :** Ajout des m√©triques de temps de calcul √† l'analyse statistique

---

## üéØ R√©sum√©

Le module d'analyse statistique de MATILDA inclut maintenant l'analyse et la comparaison des **m√©triques de temps de calcul** pour tous les algorithmes et datasets.

## ‚ú® Nouveaut√©s

### üìà Nouvelles M√©triques Analys√©es

| M√©trique | Description | Unit√© |
|----------|-------------|-------|
| `time_compute_compatible` | Temps pour calculer attributs compatibles | secondes |
| `time_to_compute_indexed` | Temps pour calculer attributs index√©s | secondes |
| `time_building_cg` | Temps pour construire le graphe de contraintes | secondes |

### üîß Nouvelles Fonctions

#### 1. `analyze_time_metrics()`
Analyse les m√©triques de temps √† partir des fichiers `init_time_metrics_*.json`.

```python
stats = analyze_time_metrics(Path("data/output/init_time_metrics_Bupa.json"))
# Retourne: Dict[str, PerformanceStats]
```

#### 2. `compare_time_metrics()`
Compare les temps de calcul entre deux algorithmes/datasets.

```python
comp = compare_time_metrics(
    time_file1, time_file2,
    "Algorithm1", "Algorithm2"
)
# Retourne: Dict avec diff√©rences absolues et en pourcentage
```

#### 3. `generate_statistical_report()` - Mise √† jour
Inclut maintenant automatiquement l'analyse des temps.

```python
report = generate_statistical_report(
    results_dir,
    include_time_metrics=True  # Par d√©faut
)
# report["time_metrics"] et report["time_comparisons"]
```

## üìä R√©sultats G√©n√©r√©s

### Rapport JSON

```json
{
  "time_metrics": {
    "MATILDA": {
      "Bupa": {
        "time_building_cg": {
          "mean": 0.038717,
          "std": 0.0,
          ...
        }
      }
    }
  },
  "time_comparisons": {
    "MATILDA_vs_SPIDER_Bupa_time": {
      "time_building_cg": {
        "MATILDA_time": 0.038717,
        "SPIDER_time": 0.035925,
        "difference": 0.002792,
        "percent_difference": 7.77,
        "faster_algorithm": "SPIDER"
      }
    }
  }
}
```

### Rapport Markdown

**Nouvelles sections ajout√©es :**

1. **Compute Time Metrics** - Tableau des temps par algorithme/dataset
2. **Compute Time Comparisons** - Comparaisons d√©taill√©es avec % de diff√©rence

## üöÄ Utilisation

### Script de G√©n√©ration

```bash
# G√©n√©rer rapport complet avec temps
python generate_statistics_report.py --markdown --verbose
```

**Output console :**
```
======================================================================
Compute Time Metrics
======================================================================

MATILDA:
  Bupa:
    time_compute_compatible: 0.037848s
    time_to_compute_indexed: 0.038163s
    time_building_cg: 0.038717s

======================================================================
Compute Time Comparisons
======================================================================

MATILDA_vs_SPIDER_Bupa_time:
  time_building_cg: SPIDER is faster by 0.002792s (7.77%)
```

### API Programmatique

```python
from utils.statistical_analysis import analyze_time_metrics, compare_time_metrics

# Analyser
stats = analyze_time_metrics(time_file)
print(f"Temps de construction CG: {stats['time_building_cg'].mean:.6f}s")

# Comparer
comp = compare_time_metrics(file1, file2, "Algo1", "Algo2")
print(f"Plus rapide: {comp['time_building_cg']['faster_algorithm']}")
print(f"Diff√©rence: {comp['time_building_cg']['percent_difference']:.2f}%")
```

## üß™ Tests

### Script de Test
```bash
python test_time_metrics.py
```

**R√©sultat :**
```
======================================================================
Testing Time Metrics Analysis Module
======================================================================

Test 1: Analyze Time Metrics
‚úì Successfully analyzed time metrics
  Metrics found: 3

Test 2: Compare Time Metrics  
‚úì Successfully compared time metrics
  Metrics compared: 3

======================================================================
‚úì All tests passed!
======================================================================
```

## üìÅ Fichiers Modifi√©s/Cr√©√©s

### Modifi√©s

| Fichier | Lignes Ajout√©es | Description |
|---------|----------------|-------------|
| `src/utils/statistical_analysis.py` | ~150 | Nouvelles fonctions d'analyse temps |
| `generate_statistics_report.py` | ~100 | Sections temps dans rapport Markdown |

### Cr√©√©s

| Fichier | Lignes | Description |
|---------|--------|-------------|
| `test_time_metrics.py` | 155 | Tests unitaires pour analyse temps |
| `TIME_METRICS_ANALYSIS.md` | 400+ | Documentation compl√®te |
| `TIME_METRICS_UPDATE.md` | Ce fichier | R√©sum√© de la mise √† jour |

## üìà Exemple de Sortie

### Statistiques Descriptives

```
MATILDA - Bupa:
  time_compute_compatible: 0.037848s
  time_to_compute_indexed: 0.038163s  
  time_building_cg: 0.038717s
```

### Comparaisons

```
Bupa vs BupaImperfect:
  time_building_cg:
    Bupa: 0.038717s
    BupaImperfect: 0.034235s
    Diff√©rence: 0.004482s (13.09%)
    Plus rapide: BupaImperfect
```

## üéì Cas d'Usage

### 1. Identification des Goulots d'√âtranglement

```python
# Trouver l'op√©ration la plus lente
stats = analyze_time_metrics(time_file)
slowest = max(stats.items(), key=lambda x: x[1].mean)
print(f"Op√©ration la plus lente: {slowest[0]} ({slowest[1].mean:.6f}s)")
```

### 2. Comparaison d'Algorithmes

```python
# Identifier l'algorithme le plus rapide
comp = compare_time_metrics(algo1_file, algo2_file, "MATILDA", "SPIDER")
for metric, data in comp.items():
    if data['faster_algorithm'] == 'MATILDA':
        print(f"MATILDA plus rapide pour {metric}")
```

### 3. Rapport pour Publication

```bash
# G√©n√©rer rapport complet Markdown
python generate_statistics_report.py --markdown

# Utiliser les tableaux dans l'article scientifique
cat data/output/statistical_analysis_report.md
```

## ‚ö° Performance

- **Overhead minimal** : Analyse en O(n) sur les fichiers temps
- **Int√©gration transparente** : Activ√©e par d√©faut
- **Rapide** : < 1s pour analyser tous les fichiers

## üîç Limitations et Solutions

### Limitation : Valeurs Uniques

Les m√©triques de temps sont des valeurs uniques par run (pas de distribution).

**Impact :**
- ‚úì Comparaisons absolues disponibles
- ‚úì Pourcentages de diff√©rence calcul√©s
- ‚úó Tests de significativit√© impossibles (n√©cessitent N runs)

**Solution pour tests statistiques :**

```python
# Ex√©cuter N fois pour obtenir distribution
times_list = []
for i in range(30):
    times_list.append(run_and_measure())

# Puis appliquer tests standards
t_test_result = perform_t_test(times_algo1, times_algo2, "time_building_cg")
```

## üîÑ Compatibilit√©

- ‚úÖ **R√©trocompatible** : Anciens scripts fonctionnent sans modification
- ‚úÖ **Optionnel** : Peut √™tre d√©sactiv√© avec `include_time_metrics=False`
- ‚úÖ **Automatique** : D√©tection automatique des fichiers `init_time_metrics_*.json`

## üìù Configuration

### Par D√©faut (Aucune Config N√©cessaire)

Les m√©triques de temps sont automatiquement analys√©es si les fichiers existent.

### D√©sactivation (si besoin)

```python
report = generate_statistical_report(
    results_dir,
    include_time_metrics=False  # D√©sactive analyse temps
)
```

## ‚úÖ Checklist d'Impl√©mentation

- [x] Fonction `analyze_time_metrics()` cr√©√©e
- [x] Fonction `compare_time_metrics()` cr√©√©e  
- [x] `generate_statistical_report()` mise √† jour
- [x] Section temps dans rapport Markdown
- [x] Affichage verbeux dans console
- [x] Tests unitaires cr√©√©s et valid√©s
- [x] Documentation compl√®te r√©dig√©e
- [x] Exemples d'utilisation fournis

## üéâ R√©sultat Final

### Avant
```json
{
  "statistics": {...},
  "comparisons": {...},
  "summary": {...}
}
```

### Apr√®s
```json
{
  "statistics": {...},
  "comparisons": {...},
  "time_metrics": {...},          // ‚Üê NOUVEAU
  "time_comparisons": {...},      // ‚Üê NOUVEAU
  "summary": {
    "total_time_comparisons": 8   // ‚Üê NOUVEAU
  }
}
```

---

## üìö Documentation

- **Guide complet** : [TIME_METRICS_ANALYSIS.md](TIME_METRICS_ANALYSIS.md)
- **Documentation g√©n√©rale** : [STATISTICS_FEATURE.md](STATISTICS_FEATURE.md)
- **Tests** : `python test_time_metrics.py`

## üÜò Support

Pour toute question sur l'analyse des temps :

```bash
# Voir les temps en mode verbeux
python generate_statistics_report.py --verbose

# Tester les fonctions
python test_time_metrics.py

# Lire la documentation
cat TIME_METRICS_ANALYSIS.md
```

---

**‚úì L'analyse des m√©triques de temps de calcul est maintenant pleinement op√©rationnelle !**

Les statistiques incluent d√©sormais :
- üìà Statistiques de performance (accuracy, confidence)
- ‚è±Ô∏è M√©triques de temps de calcul
- üî¨ Tests de significativit√©
- üìä Rapports JSON et Markdown complets
