# Nouvelle Fonctionnalit√© : Analyse Statistique des Performances

## R√©sum√©

MATILDA int√®gre maintenant un **module d'analyse statistique complet** qui calcule automatiquement :

‚úÖ **Statistiques descriptives** : moyenne, √©cart-type, m√©diane, min/max, intervalles de confiance  
‚úÖ **Tests de significativit√©** : tests t, tests de Mann-Whitney U  
‚úÖ **Tailles d'effet** : Cohen's d, corr√©lation rank-biserial  
‚úÖ **Rapports comparatifs** : comparaisons automatiques entre algorithmes

## Fichiers Cr√©√©s

### Module Principal
- **`src/utils/statistical_analysis.py`** - Module complet d'analyse statistique (374 lignes)

### Scripts
- **`generate_statistics_report.py`** - G√©n√©rateur de rapports statistiques
- **`test_statistics.py`** - Tests unitaires (‚úì tous passent)

### Documentation
- **`STATISTICS_FEATURE.md`** - Documentation compl√®te de la fonctionnalit√©
- **`STATISTICS_README.md`** - Ce fichier

## Fichiers Modifi√©s

### Configuration
- **`src/config.yaml`** - Ajout des options statistiques
  ```yaml
  results:
    compute_statistics: true
    generate_statistical_report: true
    statistical_report_name: "statistical_analysis_report.json"
  ```

### Code Principal
- **`src/main.py`** - Int√©gration de l'analyse statistique dans le pipeline

## üöÄ Utilisation Rapide

### 1. Configuration (config.yaml)

```yaml
results:
  compute_statistics: true           # Active les statistiques
  generate_statistical_report: true  # G√©n√®re rapport global
```

### 2. Ex√©cution Automatique

```bash
python src/main.py
```

**R√©sultats g√©n√©r√©s :**
- `ALGORITHM_DATASET_results.json` - R√©sultats des r√®gles
- `ALGORITHM_DATASET_statistics.json` - **Nouveau** : Statistiques descriptives
- `statistical_analysis_report.json` - **Nouveau** : Rapport comparatif global

### 3. G√©n√©ration de Rapports Avanc√©s

```bash
# Rapport complet avec Markdown
python generate_statistics_report.py --markdown --verbose

# R√©sultats :
# - statistical_analysis_report.json
# - statistical_analysis_report.md
```

## üìä Exemples de Sortie

### Statistiques Descriptives (JSON)

```json
{
  "accuracy": {
    "metric": "accuracy",
    "mean": 0.8750,
    "std": 0.0645,
    "median": 0.8800,
    "min": 0.7500,
    "max": 0.9500,
    "count": 150,
    "ci_95_lower": 0.8645,
    "ci_95_upper": 0.8855
  }
}
```

### Rapport Comparatif

```
======================================================================
Summary
======================================================================
Algorithms analyzed: 4
Datasets analyzed: 4
Comparisons performed: 8

======================================================================
Significant Differences Found (3)
======================================================================
  MATILDA vs SPIDER (accuracy)
    p-value: 0.0012, effect size: 0.7523
  MATILDA vs ANYBURL (confidence)
    p-value: 0.0000, effect size: 2.1456
```

## üí° Utilisation Programmatique

### Analyser un Fichier de R√©sultats

```python
from utils.statistical_analysis import analyze_rules_performance

stats = analyze_rules_performance(
    Path("data/output/MATILDA_Bupa_results.json")
)

for metric, stat in stats.items():
    print(f"{metric}: Œº={stat.mean:.4f}, œÉ={stat.std:.4f}")
```

### Comparer Deux Algorithmes

```python
from utils.statistical_analysis import compare_algorithms

comparisons = compare_algorithms(
    Path("data/output/MATILDA_Bupa_results.json"),
    Path("data/output/SPIDER_Bupa_results.json"),
    "MATILDA", "SPIDER"
)

for metric, test in comparisons.items():
    if test.is_significant:
        print(f"{metric}: Diff√©rence significative (p={test.p_value:.4f})")
```

### G√©n√©rer Rapport Global

```python
from utils.statistical_analysis import generate_statistical_report

report = generate_statistical_report(
    Path("data/output"),
    Path("report.json")
)

print(f"Comparaisons: {report['summary']['total_comparisons']}")
```

## üìà Statistiques Disponibles

### Descriptives

| Statistique | Description |
|-------------|-------------|
| Mean (Œº) | Moyenne |
| Std (œÉ) | √âcart-type |
| Median | M√©diane |
| Min/Max | Valeurs extr√™mes |
| 95% CI | Intervalle de confiance |

### Tests de Significativit√©

| Test | Usage | Sortie |
|------|-------|--------|
| **t-test** | Comparer moyennes (param√©trique) | t-statistic, p-value, Cohen's d |
| **Mann-Whitney U** | Comparer distributions (non-param√©trique) | U-statistic, p-value, rank-biserial |

### Interpr√©tation

- **p < 0.05** : Diff√©rence statistiquement significative ‚úì
- **p ‚â• 0.05** : Pas de diff√©rence significative ‚úó

**Taille d'effet (Cohen's d) :**
- Petit : 0.2
- Moyen : 0.5
- Grand : 0.8

## üß™ Tests

```bash
# Ex√©cuter les tests
python test_statistics.py
```

**R√©sultat :**

```
======================================================================
Testing Statistical Analysis Module
======================================================================

Testing compute_statistics...
  ‚úì Passed!

Testing t-test...
  ‚úì Passed!

Testing Mann-Whitney U test...
  ‚úì Passed!

Testing JSON serialization...
  ‚úì Passed!

Testing analyze_rules_performance...
  ‚úì Passed!

======================================================================
‚úì All tests passed!
======================================================================
```

## üéØ Cas d'Usage

### 1. √âvaluer la Stabilit√© d'un Algorithme

```python
# Calculer √©cart-type pour √©valuer la variabilit√©
stats = analyze_rules_performance(rules_file)
print(f"Accuracy: {stats['accuracy'].mean:.4f} ¬± {stats['accuracy'].std:.4f}")

# Faible std ‚Üí algorithme stable
# √âlev√© std ‚Üí r√©sultats variables
```

### 2. Comparer Algorithmes

```python
# Tester si MATILDA est significativement meilleur que SPIDER
comparison = compare_algorithms(matilda_file, spider_file, "MATILDA", "SPIDER")

if comparison['accuracy'].is_significant:
    print("MATILDA est significativement diff√©rent de SPIDER")
    print(f"Taille d'effet: {comparison['accuracy'].effect_size:.4f}")
```

### 3. Rapport de Publication

```bash
# G√©n√©rer rapport complet pour article scientifique
python generate_statistics_report.py --markdown --verbose

# Inclure :
# - statistical_analysis_report.md dans le paper
# - Tableaux de statistiques descriptives
# - R√©sultats des tests de significativit√©
```

## üìÅ Structure des Fichiers G√©n√©r√©s

```
data/output/
‚îú‚îÄ‚îÄ MATILDA_Bupa_results.json              # R√®gles d√©couvertes
‚îú‚îÄ‚îÄ MATILDA_Bupa_statistics.json           # ‚Üê NOUVEAU : Stats descriptives
‚îú‚îÄ‚îÄ SPIDER_Bupa_results.json
‚îú‚îÄ‚îÄ SPIDER_Bupa_statistics.json            # ‚Üê NOUVEAU
‚îú‚îÄ‚îÄ statistical_analysis_report.json       # ‚Üê NOUVEAU : Rapport global
‚îî‚îÄ‚îÄ statistical_analysis_report.md         # ‚Üê NOUVEAU : Version Markdown
```

## ‚öôÔ∏è Options de Configuration

| Option | Description | D√©faut |
|--------|-------------|--------|
| `compute_statistics` | Calculer stats par fichier | `false` |
| `generate_statistical_report` | G√©n√©rer rapport global | `false` |
| `statistical_report_name` | Nom du fichier rapport | `statistical_analysis_report.json` |

## üîß API Compl√®te

### Fonctions Principales

```python
# Statistiques descriptives
compute_statistics(values, metric_name) -> PerformanceStats

# Tests de significativit√©
perform_t_test(group1, group2, ...) -> SignificanceTest
perform_mannwhitneyu_test(group1, group2, ...) -> SignificanceTest

# Analyse de fichiers
analyze_rules_performance(rules_file) -> Dict[str, PerformanceStats]
compare_algorithms(file1, file2, ...) -> Dict[str, SignificanceTest]

# Rapports
generate_statistical_report(results_dir) -> Dict
```

### Classes

```python
@dataclass
class PerformanceStats:
    metric_name: str
    mean: float
    std: float
    median: float
    min: float
    max: float
    count: int
    confidence_interval_95: Tuple[float, float]

@dataclass
class SignificanceTest:
    test_name: str
    metric: str
    group1_name: str
    group2_name: str
    statistic: float
    p_value: float
    is_significant: bool
    effect_size: Optional[float]
```

## üìö Documentation

- **`STATISTICS_FEATURE.md`** - Documentation compl√®te
  - Exemples d√©taill√©s
  - API reference
  - Bonnes pratiques
  - Interpr√©tation des r√©sultats

## ‚úÖ Avantages

1. **Automatique** - Int√©gr√© dans le workflow MATILDA
2. **Complet** - Statistiques + tests de significativit√©
3. **Flexible** - Utilisation autonome ou int√©gr√©e
4. **Scientifique** - Tests statistiques standards
5. **Exportable** - Formats JSON et Markdown

## üéì R√©f√©rences Scientifiques

- Cohen, J. (1988). Statistical Power Analysis
- Mann & Whitney (1947). Test of Stochastic Ordering
- Student (1908). The Probable Error of a Mean

## üîó Workflow Complet

1. **Configuration** : `config.yaml` ‚Üí activer `compute_statistics`
2. **Ex√©cution** : `python src/main.py`
3. **R√©sultats** : Statistiques automatiquement calcul√©es
4. **Rapport** : `python generate_statistics_report.py --markdown`
5. **Analyse** : Consulter les rapports JSON/Markdown

---

## üéâ R√©sultat

MATILDA offre maintenant une **analyse statistique compl√®te et automatique** des performances :

‚úÖ **Scientifiquement rigoureux** - Tests statistiques standards  
‚úÖ **Facilement interpr√©table** - Rapports clairs et d√©taill√©s  
‚úÖ **Totalement automatis√©** - Int√©gr√© dans le pipeline  
‚úÖ **Exportable** - Formats multiples (JSON, Markdown)  
‚úÖ **Test√©** - Suite de tests compl√®te  

**Impl√©mentation compl√®te et pr√™te √† l'emploi** ‚úì
